# æˆ‘çš„AIçŸ¥è¯†ç®¡å®¶ï¼šç”¨OpenClawæ‰“é€ ç¬¬äºŒå¤§è„‘

## ä¸€ã€ç¼˜èµ·ï¼šçŸ¥è¯†ç®¡ç†çš„å›°å¢ƒ

ä½œä¸ºä¸€ä¸ªæŠ€æœ¯åšä¸»å’Œå¼€å‘è€…ï¼Œæˆ‘æ¯å¤©éƒ½åœ¨å’Œæµ·é‡ä¿¡æ¯æ‰“äº¤é“ï¼š

- Twitter/X ä¸Šåˆ·åˆ°çš„æŠ€æœ¯æ–‡ç« 
- GitHub ä¸Šå‘ç°çš„å¼€æºé¡¹ç›®
- æ˜é‡‘ã€CSDN çœ‹åˆ°çš„æ•™ç¨‹
- ä¼šè®®ç¬”è®°ã€è¯»ä¹¦ç¬”è®°
- é¡¹ç›®æ–‡æ¡£ã€APIæ–‡æ¡£

è¿™äº›ä¿¡æ¯æ•£è½åœ¨å„ä¸ªè§’è½ï¼Œå½“æˆ‘éœ€è¦ç”¨åˆ°æŸæ¡çŸ¥è¯†æ—¶ï¼Œå¾€å¾€ï¼š

1. ä¾ç¨€è®°å¾—çœ‹è¿‡ï¼Œä½†æƒ³ä¸èµ·åœ¨å“ªé‡Œ
2. ç¿»éæ”¶è—å¤¹å’Œå†å²è®°å½•ï¼Œè€—æ—¶åŠå°æ—¶
3. æ‰¾åˆ°äº†ä½†å½“æ—¶æ²¡æœ‰è®°å½•æ€è€ƒï¼Œéœ€è¦é‡æ–°æ¶ˆåŒ–

**çŸ¥è¯†ç®¡ç†çš„æœ¬è´¨çŸ›ç›¾**ï¼šä¿¡æ¯è¶Šç§¯ç´¯ï¼Œæ£€ç´¢è¶Šå›°éš¾ã€‚ä¼ ç»Ÿçš„ç¬”è®°å·¥å…·ï¼ˆNotionã€Obsidianï¼‰èƒ½å­˜ï¼Œä½†ä¸èƒ½æ™ºèƒ½åœ°æ•´ç†å’Œæé†’ã€‚

ç›´åˆ°é‡è§ OpenClawï¼Œæˆ‘çªç„¶æ„è¯†åˆ°ï¼š**æˆ‘éœ€è¦çš„ä¸æ˜¯æ›´å¥½çš„ç¬”è®°å·¥å…·ï¼Œè€Œæ˜¯ä¸€ä¸ªèƒ½ä¸»åŠ¨å¸®æˆ‘ç®¡ç†çŸ¥è¯†çš„AIåŠ©æ‰‹ã€‚**

---

## äºŒã€æ–¹æ¡ˆè®¾è®¡ï¼šä¸ºä»€ä¹ˆé€‰æ‹© OpenClaw + Lighthouse

### 2.1 OpenClaw çš„ç‹¬ç‰¹ä¼˜åŠ¿

ç›¸æ¯”å…¶ä»–AIåŠ©æ‰‹ï¼ŒOpenClawæœ‰ä¸¤ä¸ªå…³é”®ç‰¹æ€§è®©æˆ‘é€‰æ‹©å®ƒï¼š

1. **æ–‡ä»¶ç³»ç»Ÿè®¿é—®æƒé™**ï¼šå¯ä»¥è¯»å†™æœ¬åœ°æ–‡ä»¶ï¼Œèƒ½å¤ŸçœŸæ­£ç®¡ç†çŸ¥è¯†åº“
2. **å‘½ä»¤æ‰§è¡Œèƒ½åŠ›**ï¼šå¯ä»¥è°ƒç”¨è„šæœ¬ï¼Œå®ç°è‡ªåŠ¨åŒ–å·¥ä½œæµ

è¿™æ„å‘³ç€ OpenClaw ä¸æ˜¯åªã€Œè¯´ã€ä¸ã€Œåšã€ï¼Œè€Œæ˜¯èƒ½çœŸæ­£æ¥ç®¡çŸ¥è¯†ç®¡ç†ä»»åŠ¡ã€‚

### 2.2 ä¸ºä»€ä¹ˆéœ€è¦äº‘ç«¯éƒ¨ç½²

- **æŒä¹…åŒ–å­˜å‚¨**ï¼šçŸ¥è¯†åº“éœ€è¦åœ¨äº‘ç«¯é•¿æœŸä¿å­˜
- **éšæ—¶è®¿é—®**ï¼šé€šè¿‡QQ/ä¼ä¸šå¾®ä¿¡éšæ—¶æŸ¥è¯¢ï¼Œä¸ä¾èµ–ç‰¹å®šè®¾å¤‡
- **å®šæœŸç»´æŠ¤**ï¼šéœ€è¦åå°å®šæœŸæ•´ç†ã€å»é‡ã€å»ºç«‹ç´¢å¼•
- **æˆæœ¬ä½**ï¼šLighthouse 2æ ¸2G é…ç½®å³å¯ï¼Œæœˆè´¹çº¦ 30 å…ƒ

### 2.3 é€‰æ‹©QQä½œä¸ºæ¥å…¥å¹³å°

æˆ‘æœ€ç»ˆé€‰æ‹©QQä½œä¸ºä¸»è¦æ¥å…¥æ¸ é“ï¼ŒåŸå› ï¼š

- QQæœºå™¨äººç”Ÿæ€æˆç†Ÿï¼Œ[go-cqhttp](https://github.com/Mrs4s/go-cqhttp) ç¨³å®šå¯é 
- ä¸ªäººä½¿ç”¨ï¼Œä¸éœ€è¦ä¼ä¸šè®¤è¯æµç¨‹
- æ”¯æŒæ–‡ä»¶ä¼ è¾“ï¼Œå¯ä»¥å‘é€æ–‡æ¡£ã€å›¾ç‰‡
- æ¶ˆæ¯ä¿å­˜æ—¶é—´é•¿ï¼Œæ–¹ä¾¿å›æº¯

---

## ä¸‰ã€Lighthouse éƒ¨ç½² OpenClaw + QQ å…¨æµç¨‹

### 3.1 è´­ä¹° Lighthouse å®ä¾‹

```bash
# æ¨èé…ç½®
CPU: 2æ ¸
å†…å­˜: 2GBï¼ˆçŸ¥è¯†åº“åœºæ™¯è¶³å¤Ÿï¼‰
ç¡¬ç›˜: 40GB SSD
ç³»ç»Ÿ: Ubuntu 22.04 LTS
å¸¦å®½: æŒ‰æµé‡è®¡è´¹
```

**è´¹ç”¨å‚è€ƒ**ï¼šçº¦ Â¥30-40/æœˆ

### 3.2 å®‰è£… OpenClaw

è…¾è®¯äº‘å·²æä¾› OpenClaw ä¸“ç”¨é•œåƒï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚å¦‚æœæ‰‹åŠ¨å®‰è£…ï¼š

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/OpenClaw/clawdbot.git /opt/openclaw
cd /opt/openclaw

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# é…ç½®å¤§æ¨¡å‹ï¼ˆä»¥ DeepSeek ä¸ºä¾‹ï¼‰
cp .env.example .env
vim .env
```

`.env` é…ç½®ï¼š

```bash
# LLM é…ç½®
LLM_API_KEY=your_deepseek_api_key
LLM_BASE_URL=https://api.deepseek.com
LLM_MODEL=deepseek-chat

# QQ æœºå™¨äººé…ç½®
QQ_BOT_ACCOUNT=ä½ çš„QQå·
QQ_BOT_PASSWORD=ä½ çš„QQå¯†ç 
```

### 3.3 é…ç½® QQ æœºå™¨äºº

ä½¿ç”¨ [go-cqhttp](https://github.com/Mrs4s/go-cqhttp) ä½œä¸º QQ åè®®å±‚ï¼š

```bash
# ä¸‹è½½ go-cqhttp
wget https://github.com/Mrs4s/go-cqhttp/releases/download/v1.2.0/go-cqhttp_linux_amd64.tar.gz
tar -xzf go-cqhttp_linux_amd64.tar.gz
cd go-cqhttp

# é¦–æ¬¡è¿è¡Œä¼šç”Ÿæˆé…ç½®æ–‡ä»¶
./go-cqhttp

# ç¼–è¾‘é…ç½®æ–‡ä»¶ config.yml
```

å…³é”®é…ç½®é¡¹ï¼š

```yaml
account:
  uin: ä½ çš„QQå·
  password: 'ä½ çš„QQå¯†ç '
  encrypt: false
  status: 0
  relogin:
    delay: 3
    interval: 3
    max-times: 0

message:
  post-format: string
  ignore-invalid-cqcode: false
  force-fragment: false
  fix-url: false
  proxy-rewrite: ''
  report-self-message: false
  remove-reply-at: false
  extra-reply-data: false
  skip-mime-scan: false

output:
  log-level: warn
  log-aging: 15
  log-force-new: true
  log-colorful: true
  debug: false

default-middlewares: &default
  access-token: ''
  filter: ''
  rate-limit:
    enabled: false
    frequency: 1
    bucket: 1

database:
  leveldb:
    enable: true

  sqlite3:
    enable: false

http:
  address: 0.0.0.0:5700
  host: ''
  port: 5700
  timeout: 5
  long-polling:
    enabled: false
  middlewares:
    <<: *default

ws:
  address: 0.0.0.0:5701
  host: ''
  port: 5701
  middlewares:
    <<: *default
```

### 3.4 å¯åŠ¨æœåŠ¡

åˆ›å»º systemd æœåŠ¡æ–‡ä»¶ï¼š

```bash
vim /etc/systemd/system/openclaw.service
```

```ini
[Unit]
Description=OpenClaw AI Bot
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/opt/openclaw
ExecStart=/usr/bin/python3 /opt/openclaw/main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
# å¯åŠ¨ go-cqhttp
systemctl start go-cqhttp
systemctl enable go-cqhttp

# å¯åŠ¨ OpenClaw
systemctl start openclaw
systemctl enable openclaw

# æŸ¥çœ‹çŠ¶æ€
systemctl status openclaw
```

**éƒ¨ç½²éªŒè¯ï¼š**

åœ¨ QQ ä¸­ç»™è‡ªå·±çš„æœºå™¨äººå‘æ¶ˆæ¯ï¼šã€Œä½ å¥½ã€

å¦‚æœæ”¶åˆ°å›å¤ï¼Œéƒ¨ç½²æˆåŠŸï¼

---

## å››ã€çŸ¥è¯†åº“æ¶æ„è®¾è®¡

### 4.1 ç›®å½•ç»“æ„

```
~/knowledge/
â”œâ”€â”€ inbox/              # æ”¶ä»¶ç®±ï¼ˆæœªæ•´ç†ï¼‰
â”‚   â”œâ”€â”€ articles/       # æ–‡ç« æ”¶è—
â”‚   â”œâ”€â”€ notes/          # ä¸´æ—¶ç¬”è®°
â”‚   â””â”€â”€ snippets/       # ä»£ç ç‰‡æ®µ
â”œâ”€â”€ processed/          # å·²æ•´ç†
â”‚   â”œâ”€â”€ tech/           # æŠ€æœ¯çŸ¥è¯†
â”‚   â”œâ”€â”€ products/       # äº§å“æ€ç»´
â”‚   â””â”€â”€ writing/        # å†™ä½œç´ æ
â”œâ”€â”€ tags/               # æ ‡ç­¾ç´¢å¼•
â””â”€â”€ search_index.json   # æœç´¢ç´¢å¼•
```

### 4.2 å…ƒæ•°æ®è§„èŒƒ

æ¯ä¸ªçŸ¥è¯†ç‚¹éƒ½é™„å¸¦ä¸€ä¸ª `metadata.yaml`ï¼š

```yaml
title: "ä½¿ç”¨Rediså®ç°åˆ†å¸ƒå¼é”çš„æœ€ä½³å®è·µ"
source: "https://cloud.tencent.com/developer/article/..."
collected_at: "2026-02-07"
tags:
  - Redis
  - åˆ†å¸ƒå¼ç³»ç»Ÿ
  - åç«¯å¼€å‘
category: "tech/backend"
importance: 8  # 1-10åˆ†
review_cycle: 90  # æ¯90å¤©å¤ä¹ ä¸€æ¬¡
related:
  - "2026-01-15-redis-pipeline.md"
  - "2025-12-20-distributed-locks.md"
notes: |
  é‡ç‚¹ï¼šRedisson çš„ watchdog æœºåˆ¶
  å¾…éªŒè¯ï¼šé«˜å¹¶å‘ä¸‹çš„æ€§èƒ½è¡¨ç°
```

---

## äº”ã€æ ¸å¿ƒåŠŸèƒ½å®ç°

### 5.1 åŠŸèƒ½ä¸€ï¼šæ™ºèƒ½æ”¶ä»¶ç®±

**ç—›ç‚¹**ï¼šçœ‹åˆ°å¥½æ–‡ç« æƒ³æ”¶è—ï¼Œä½†ä¸€ä¸ªä¸ªå¤åˆ¶ç²˜è´´å¤ªéº»çƒ¦ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šç›´æ¥å‘é€é“¾æ¥ç»™ QQ æœºå™¨äººï¼Œè‡ªåŠ¨è§£æå¹¶ä¿å­˜ã€‚

```python
# OpenClaw æŠ€èƒ½ï¼šæ”¶ä»¶ç®±åŠ©æ‰‹

import requests
import yaml
from datetime import datetime
from pathlib import Path

class InboxAssistant:
    def __init__(self, base_path="~/knowledge/inbox"):
        self.base_path = Path(base_path).expanduser()
        self.base_path.mkdir(parents=True, exist_ok=True)

    async def save_article(self, url, user_note=""):
        """
        ä¿å­˜æ–‡ç« åˆ°æ”¶ä»¶ç®±
        """
        # 1. è·å–æ–‡ç« å†…å®¹
        content = self.fetch_article(url)

        # 2. æå–å…ƒæ•°æ®
        metadata = {
            "title": content["title"],
            "source": url,
            "collected_at": datetime.now().isoformat(),
            "tags": [],
            "category": "uncategorized",
            "notes": user_note
        }

        # 3. ä¿å­˜æ–‡ä»¶
        filename = f"{datetime.now().strftime('%Y%m%d-%H%M%S')}.md"
        filepath = self.base_path / "articles" / filename

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# {metadata['title']}\n\n")
            f.write(f"> æ¥æºï¼š{url}\n")
            f.write(f"> æ”¶è—æ—¶é—´ï¼š{metadata['collected_at']}\n\n")
            if user_note:
                f.write(f"**å¤‡æ³¨**ï¼š{user_note}\n\n")
            f.write("---\n\n")
            f.write(content["body"])

        # 4. ä¿å­˜å…ƒæ•°æ®
        metadata_path = filepath.with_suffix('.yaml')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            yaml.dump(metadata, f, allow_unicode=True)

        return f"å·²ä¿å­˜åˆ°æ”¶ä»¶ç®±ï¼š{filename}"

    def fetch_article(self, url):
        """
        è§£ææ–‡ç« å†…å®¹ï¼ˆä½¿ç”¨ Readability APIï¼‰
        """
        # è¿™é‡Œå¯ä»¥é›†æˆ mercury-web-parser æˆ– readability-lxml
        # ç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…éœ€è¦å¤„ç†å„ç§ç½‘ç«™æ ¼å¼
        response = requests.get(url)
        # ... è§£æé€»è¾‘ ...
        return {"title": "æ–‡ç« æ ‡é¢˜", "body": "æ–‡ç« å†…å®¹"}
```

**ä½¿ç”¨æ•ˆæœï¼š**

```
æˆ‘ï¼šæ”¶è— https://cloud.tencent.com/developer/article/2627198
   å¤‡æ³¨ï¼šOpenClawæ¯”èµ›ä¿¡æ¯

OpenClawï¼š
âœ… å·²ä¿å­˜åˆ°æ”¶ä»¶ç®±

æ–‡ç« ï¼šçƒ­ç‚¹æŠ€æœ¯æœ‰å¥–å¾æ–‡ | ç©è½¬ OpenClaw äº‘ç«¯åˆ›æ„å®è·µèµ›
è·¯å¾„ï¼šinbox/articles/20260207-143022.md
```

---

### 5.2 åŠŸèƒ½äºŒï¼šè¯­ä¹‰æ£€ç´¢

**ç—›ç‚¹**ï¼šè®°å¾—å†…å®¹ä½†ä¸è®°å¾—å…³é”®è¯ï¼Œæœç´¢å¾ˆéš¾æ‰¾åˆ°ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šç”¨å‘é‡æ•°æ®åº“å®ç°è¯­ä¹‰æœç´¢ã€‚

```python
# è¯­ä¹‰æœç´¢å®ç°

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from pathlib import Path

class SemanticSearch:
    def __init__(self):
        # åŠ è½½ä¸­æ–‡å‘é‡æ¨¡å‹
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.index_path = Path("~/knowledge/search_index.faiss").expanduser()
        self.metadata_path = Path("~/knowledge/search_metadata.json").expanduser()

        # åŠ è½½æˆ–åˆ›å»ºç´¢å¼•
        if self.index_path.exists():
            self.index = faiss.read_index(str(self.index_path))
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                import json
                self.metadata = json.load(f)
        else:
            self.index = None
            self.metadata = []

    def build_index(self, knowledge_dir="~/knowledge/processed"):
        """
        æ„å»ºå‘é‡ç´¢å¼•
        """
        knowledge_dir = Path(knowledge_dir).expanduser()
        documents = []

        # éå†æ‰€æœ‰ markdown æ–‡ä»¶
        for md_file in knowledge_dir.rglob("*.md"):
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # è¯»å–å…ƒæ•°æ®
            meta_file = md_file.with_suffix('.yaml')
            metadata = {}
            if meta_file.exists():
                with open(meta_file, 'r', encoding='utf-8') as f:
                    metadata = yaml.safe_load(f)

            documents.append({
                "path": str(md_file),
                "content": content,
                "metadata": metadata
            })

        # ç”Ÿæˆå‘é‡
        texts = [self._extract_text(doc) for doc in documents]
        embeddings = self.model.encode(texts)

        # æ„å»º FAISS ç´¢å¼•
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings.astype('float32'))
        self.metadata = documents

        # ä¿å­˜ç´¢å¼•
        faiss.write_index(self.index, str(self.index_path))
        with open(self.metadata_path, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)

    def search(self, query, top_k=5):
        """
        è¯­ä¹‰æœç´¢
        """
        query_vector = self.model.encode([query])
        distances, indices = self.index.search(query_vector.astype('float32'), top_k)

        results = []
        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
            if idx < len(self.metadata):
                doc = self.metadata[idx]
                results.append({
                    "rank": i + 1,
                    "score": float(1 / (1 + dist)),  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                    "title": doc["metadata"].get("title", "æœªå‘½å"),
                    "path": doc["path"],
                    "snippet": self._extract_snippet(doc["content"], query)
                })

        return results

    def _extract_text(self, doc):
        """æå–ç”¨äºå‘é‡åŒ–æ–‡æœ¬"""
        # ç»„åˆæ ‡é¢˜ã€æ ‡ç­¾ã€æ­£æ–‡å‰500å­—
        meta = doc["metadata"]
        text_parts = [
            meta.get("title", ""),
            " ".join(meta.get("tags", [])),
            doc["content"][:500]
        ]
        return " ".join(text_parts)

    def _extract_snippet(self, content, query, max_length=200):
        """æå–åŒ…å«å…³é”®è¯çš„ç‰‡æ®µ"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥ç”¨æ›´æ™ºèƒ½çš„åŒ¹é…
        return content[:max_length] + "..."
```

**ä½¿ç”¨æ•ˆæœï¼š**

```
æˆ‘ï¼šæœç´¢ å…³äºRedisåˆ†å¸ƒå¼é”çš„å†…å®¹

OpenClawï¼š
ğŸ” æ‰¾åˆ° 3 æ¡ç›¸å…³ç»“æœï¼š

1. ã€ç›¸å…³åº¦ 92%ã€‘ä½¿ç”¨Rediså®ç°åˆ†å¸ƒå¼é”çš„æœ€ä½³å®è·µ
   è·¯å¾„ï¼šprocessed/tech/2025-12-15-redis-lock.md
   æ‘˜è¦ï¼šRediså®ç°åˆ†å¸ƒå¼é”éœ€è¦æ³¨æ„...Redissonçš„watchdogæœºåˆ¶ä¼šè‡ªåŠ¨ç»­æœŸ...

2. ã€ç›¸å…³åº¦ 78%ã€‘åˆ†å¸ƒå¼ç³»ç»Ÿå¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ
   è·¯å¾„ï¼šprocessed/tech/2025-11-20-distributed-system.md
   æ‘˜è¦ï¼šåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œé”æ˜¯...ä¹Ÿå¯ä»¥ä½¿ç”¨Zookeeperå®ç°...

3. ã€ç›¸å…³åº¦ 65%ã€‘Redisæ€§èƒ½ä¼˜åŒ–å®è·µ
   è·¯å¾„ï¼šprocessed/tech/2025-10-05-redis-optimization.md
   æ‘˜è¦ï¼šRedisçš„å•çº¿ç¨‹æ¨¡å‹...ç½‘ç»œIO...

éœ€è¦æŸ¥çœ‹å“ªç¯‡çš„è¯¦ç»†å†…å®¹ï¼Ÿ
```

---

### 5.3 åŠŸèƒ½ä¸‰ï¼šæ™ºèƒ½æ•´ç†

**ç—›ç‚¹**ï¼šæ”¶ä»¶ç®±å †ç§¯äº†å¾ˆå¤šæœªæ•´ç†çš„å†…å®¹ï¼Œæ‡’å¾—æ‰‹åŠ¨åˆ†ç±»ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šæ¯å‘¨è‡ªåŠ¨åˆ†ææ”¶ä»¶ç®±å†…å®¹ï¼Œæ™ºèƒ½åˆ†ç±»å¹¶ç§»åŠ¨ã€‚

```python
# æ™ºèƒ½æ•´ç†è„šæœ¬

import shutil
from pathlib import Path
from openai import OpenAI

class KnowledgeOrganizer:
    def __init__(self):
        self.client = OpenAI()  # ä½¿ç”¨ DeepSeek API
        self.inbox_path = Path("~/knowledge/inbox/articles").expanduser()
        self.processed_path = Path("~/knowledge/processed").expanduser()

    def organize(self):
        """
        æ•´ç†æ”¶ä»¶ç®±
        """
        unorganized = list(self.inbox_path.glob("*.md"))

        if not unorganized:
            return "æ”¶ä»¶ç®±ä¸ºç©ºï¼Œæ— éœ€æ•´ç†"

        results = []

        for file in unorganized:
            # è¯»å–å†…å®¹
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()

            # AI åˆ†ç±»
            category = self._classify_content(content)
            tags = self._extract_tags(content)
            title = self._extract_title(content)

            # ç§»åŠ¨åˆ°å¯¹åº”ç›®å½•
            target_dir = self.processed_path / category
            target_dir.mkdir(parents=True, exist_ok=True)

            target_file = target_dir / file.name
            shutil.move(str(file), str(target_file))

            # æ›´æ–°å…ƒæ•°æ®
            self._update_metadata(target_file, {
                "category": category,
                "tags": tags,
                "organized_at": datetime.now().isoformat()
            })

            results.append(f"âœ“ {title[:30]} â†’ {category}")

        return "\n".join(results)

    def _classify_content(self, content):
        """
        AI åˆ†ç±»
        """
        prompt = f"""
        è¯·å°†ä»¥ä¸‹å†…å®¹åˆ†ç±»åˆ°è¿™äº›ç±»åˆ«ä¹‹ä¸€ï¼š
        - tech/backendï¼ˆåç«¯å¼€å‘ï¼‰
        - tech/frontendï¼ˆå‰ç«¯å¼€å‘ï¼‰
        - tech/devopsï¼ˆè¿ç»´éƒ¨ç½²ï¼‰
        - productsï¼ˆäº§å“æ€ç»´ï¼‰
        - writingï¼ˆå†™ä½œç´ æï¼‰

        å†…å®¹ï¼š
        {content[:1000]}

        åªè¿”å›ç±»åˆ«åç§°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
        """

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )

        category = response.choices[0].message.content.strip()
        return category

    def _extract_tags(self, content):
        """æå–æ ‡ç­¾"""
        # ç±»ä¼¼å®ç°
        return ["AIæå–çš„æ ‡ç­¾"]

    def _extract_title(self, content):
        """æå–æ ‡é¢˜"""
        lines = content.split('\n')
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        return "æœªå‘½å"
```

**ä½¿ç”¨æ•ˆæœï¼š**

```
æˆ‘ï¼šæ•´ç†æ”¶ä»¶ç®±

OpenClawï¼š
ğŸ—‚ï¸ æ­£åœ¨æ•´ç†æ”¶ä»¶ç®±ï¼ˆå…± 15 ç¯‡æœªæ•´ç†ï¼‰

âœ“ ç©è½¬ OpenClaw äº‘ç«¯åˆ›æ„å®è·µèµ› â†’ tech/devops
âœ“ React æ€§èƒ½ä¼˜åŒ–æŠ€å·§ â†’ tech/frontend
âœ“ äº§å“ç»ç†å¦‚ä½•å†™PRD â†’ products
âœ“ 2025å¹´æŠ€æœ¯è¶‹åŠ¿åˆ†æ â†’ tech/backend
...

æ•´ç†å®Œæˆï¼æ”¶ä»¶ç®±å·²æ¸…ç©ºã€‚
å·²è§¦å‘ç´¢å¼•é‡å»ºï¼Œæ–°å†…å®¹å¯ç«‹å³æœç´¢ã€‚
```

---

### 5.4 åŠŸèƒ½å››ï¼šå®šæœŸå¤ä¹ æé†’

**ç—›ç‚¹**ï¼šæ”¶è—äº†å¾ˆå¤šå†…å®¹ï¼Œä½†ä»æ¥ä¸å»çœ‹ï¼Œç­‰äºç™½æ”¶è—ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šæ ¹æ®é‡è¦æ€§è¯„åˆ†å’Œå¤ä¹ å‘¨æœŸï¼Œæ¯å¤©æ¨é€éœ€è¦å¤ä¹ çš„å†…å®¹ã€‚

```python
# å¤ä¹ æé†’ç³»ç»Ÿ

import schedule
import time
from datetime import datetime, timedelta

class ReviewSystem:
    def __init__(self, metadata_path="~/knowledge/search_metadata.json"):
        self.metadata_path = Path(metadata_path).expanduser()
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            self.knowledge = json.load(f)

    def get_due_for_review(self):
        """
        è·å–ä»Šå¤©éœ€è¦å¤ä¹ çš„å†…å®¹
        """
        today = datetime.now()
        due_items = []

        for item in self.knowledge:
            metadata = item.get("metadata", {})

            # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†å¤ä¹ å‘¨æœŸ
            review_cycle = metadata.get("review_cycle")
            if not review_cycle:
                continue

            # æ£€æŸ¥ä¸Šæ¬¡å¤ä¹ æ—¶é—´
            last_review = metadata.get("last_reviewed_at")
            if not last_review:
                # ä»æœªå¤ä¹ è¿‡ï¼ŒæŒ‰æ”¶è—æ—¶é—´ç®—
                last_review = metadata.get("collected_at")

            if last_review:
                last_review_date = datetime.fromisoformat(last_review)
                next_review = last_review_date + timedelta(days=review_cycle)

                if next_review <= today:
                    due_items.append({
                        "title": metadata.get("title", "æœªå‘½å"),
                        "importance": metadata.get("importance", 5),
                        "last_reviewed": last_review,
                        "path": item["path"]
                    })

        # æŒ‰é‡è¦æ€§æ’åº
        due_items.sort(key=lambda x: x["importance"], reverse=True)
        return due_items[:5]  # æ¯å¤©æœ€å¤š5æ¡

    def send_review_reminder(self):
        """
        å‘é€å¤ä¹ æé†’
        """
        due_items = self.get_due_for_review()

        if not due_items:
            return

        message = "ğŸ“š ä»Šæ—¥çŸ¥è¯†å¤ä¹ æé†’\n\n"

        for i, item in enumerate(due_items, 1):
            message += f"{i}. {item['title']}\n"
            message += f"   é‡è¦æ€§ï¼š{'â­' * (item['importance'] // 2)}\n"
            message += f"   ä¸Šæ¬¡å¤ä¹ ï¼š{item['last_reviewed'][:10]}\n\n"

        message += "å›å¤ 'å¤ä¹  1-5' æŸ¥çœ‹è¯¦æƒ…ï¼Œæˆ– 'å®Œæˆ 1-5' æ ‡è®°ä¸ºå·²å¤ä¹ "

        # å‘é€åˆ° QQ
        send_qq_message(message)
```

**ä½¿ç”¨æ•ˆæœï¼š**

```
OpenClawï¼ˆæ¯å¤©æ—©ä¸Š9ç‚¹è‡ªåŠ¨å‘é€ï¼‰ï¼š
ğŸ“š ä»Šæ—¥çŸ¥è¯†å¤ä¹ æé†’

1. ä½¿ç”¨Rediså®ç°åˆ†å¸ƒå¼é”çš„æœ€ä½³å®è·µ
   é‡è¦æ€§ï¼šâ­â­â­â­
   ä¸Šæ¬¡å¤ä¹ ï¼š2025-11-09

2. Goè¯­è¨€å¹¶å‘æ¨¡å¼è¯¦è§£
   é‡è¦æ€§ï¼šâ­â­â­â­
   ä¸Šæ¬¡å¤ä¹ ï¼š2025-12-01

3. äº§å“ç»ç†å¦‚ä½•å†™PRD
   é‡è¦æ€§ï¼šâ­â­â­
   ä¸Šæ¬¡å¤ä¹ ï¼š2025-10-15

å›å¤ 'å¤ä¹  1-5' æŸ¥çœ‹è¯¦æƒ…ï¼Œæˆ– 'å®Œæˆ 1-5' æ ‡è®°ä¸ºå·²å¤ä¹ 
```

---

## å…­ã€éƒ¨ç½²æˆæœ¬ä¸æ”¶ç›Š

### 6.1 æˆæœ¬åˆ†æ

| é¡¹ç›® | è´¹ç”¨ | å¤‡æ³¨ |
|-----|------|------|
| Lighthouseï¼ˆ2æ ¸2Gï¼‰ | Â¥30-40/æœˆ | çŸ¥è¯†åº“åœºæ™¯é…ç½® |
| åŸŸåï¼ˆå¯é€‰ï¼‰ | Â¥10/å¹´ | æ–¹ä¾¿è®¿é—® |
| LLM APIï¼ˆDeepSeekï¼‰ | Â¥5-20/æœˆ | å–å†³äºä½¿ç”¨é¢‘ç‡ |
| **æœˆåº¦æ€»æˆæœ¬** | **Â¥35-60/æœˆ** | |

### 6.2 å®é™…æ”¶ç›Š

ä½¿ç”¨ 3 ä¸ªæœˆåçš„æ•ˆæœï¼š

- **æ”¶è—æ•ˆç‡æå‡ 10 å€**ï¼šä»ã€Œæ‡’å¾—æ”¶è—ã€åˆ°ã€Œéšæ‰‹æ”¶è—ã€
- **æ£€ç´¢æ—¶é—´å‡å°‘ 80%**ï¼šè¯­ä¹‰æœç´¢ vs å…³é”®è¯æœç´¢
- **çŸ¥è¯†å¤ç”¨ç‡æå‡ 3 å€**ï¼šå®šæœŸå¤ä¹  vs æ°¸ä¹…é—å¿˜
- **å†™ä½œç´ æåº“ç§¯ç´¯**ï¼š200+ ç¯‡ç²¾é€‰æ–‡ç« ï¼Œéšæ—¶è°ƒç”¨

**æŠ•å…¥äº§å‡ºæ¯”**ï¼šæ¯æœˆ 50 å…ƒï¼Œæ¢å–çš„æ˜¯è‡ªå·±çš„ã€Œç¬¬äºŒå¤§è„‘ã€ã€‚

---

## ä¸ƒã€æ‰©å±•æ€è·¯

### 7.1 å¤šæ¨¡æ€çŸ¥è¯†åº“

ç›®å‰åªæ”¯æŒæ–‡æœ¬ï¼Œæœªæ¥å¯ä»¥ï¼š

- å›¾ç‰‡è¯†åˆ«ï¼šä¿å­˜æŠ€æœ¯æ¶æ„å›¾ã€æ€ç»´å¯¼å›¾
- PDF è§£æï¼šç›´æ¥æ”¶è—è®ºæ–‡ã€ç”µå­ä¹¦ç« èŠ‚
- éŸ³é¢‘è½¬æ–‡å­—ï¼šä¼šè®®å½•éŸ³ç›´æ¥è½¬æˆç¬”è®°

### 7.2 çŸ¥è¯†å›¾è°±

å»ºç«‹çŸ¥è¯†ç‚¹ä¹‹é—´çš„å…³è”ï¼š

```mermaid
graph LR
    A[Redisåˆ†å¸ƒå¼é”] --> B[Redisson]
    A --> C[Redlockç®—æ³•]
    A --> D[é«˜å¹¶å‘åœºæ™¯]
    B --> E[Watchdogæœºåˆ¶]
    C --> F[ZooKeeperé”]
```

### 7.3 åä½œçŸ¥è¯†åº“

å¤šäººå…±äº«çŸ¥è¯†åº“ï¼Œé€‚åˆå›¢é˜Ÿä½¿ç”¨ï¼š

- æƒé™ç®¡ç†ï¼šä¸åŒæˆå‘˜ä¸åŒæƒé™
- è´¡çŒ®ç§¯åˆ†ï¼šæ¿€åŠ±çŸ¥è¯†åˆ†äº«
- çŸ¥è¯†å¸‚åœºï¼šå†…éƒ¨çŸ¥è¯†äº¤æ˜“

---

## å…«ã€æ€»ç»“

é€šè¿‡ OpenClaw + è…¾è®¯äº‘ Lighthouseï¼Œæˆ‘æˆåŠŸæ„å»ºäº†ä¸€ä¸ªä¸ªäººçŸ¥è¯†ç®¡ç† AI åŠ©æ‰‹ã€‚å®ƒä¸æ˜¯ç®€å•çš„ç¬”è®°å·¥å…·ï¼Œè€Œæ˜¯èƒ½å¤Ÿï¼š

1. **è‡ªåŠ¨æ”¶é›†**ï¼šéšæ‰‹å‘é€é“¾æ¥ï¼Œè‡ªåŠ¨è§£æä¿å­˜
2. **æ™ºèƒ½åˆ†ç±»**ï¼šAI ç†è§£å†…å®¹ï¼Œè‡ªåŠ¨å½’ç±»æ•´ç†
3. **è¯­ä¹‰æ£€ç´¢**ï¼šä¸é å…³é”®è¯ï¼Œé è¯­ä¹‰ç†è§£
4. **ä¸»åŠ¨æé†’**ï¼šå®šæœŸå¤ä¹ ï¼Œè®©çŸ¥è¯†çœŸæ­£æ²‰æ·€

è¿™ä¸ªç³»ç»Ÿè¿è¡Œ 3 ä¸ªæœˆæ¥ï¼Œæˆ‘å·²ç»ç§¯ç´¯äº† 200+ ç¯‡ç²¾é€‰å†…å®¹ï¼Œæ£€ç´¢æ•ˆç‡æå‡ 80%ï¼ŒçŸ¥è¯†å¤ç”¨ç‡æå‡ 3 å€ã€‚

**æœ€é‡è¦çš„æ˜¯**ï¼šå®ƒè®©ã€Œæ”¶è—ã€ä¸å†æ˜¯ä¸€ç§è™šå‡çš„æ»¡è¶³æ„Ÿï¼Œè€Œæ˜¯çœŸæ­£çš„çŸ¥è¯†ç§¯ç´¯ã€‚

çŸ¥è¯†ç®¡ç†ä¸æ˜¯ç›®çš„ï¼Œè€Œæ˜¯ä¸ºäº†åœ¨éœ€è¦çš„æ—¶å€™ï¼Œèƒ½å¤Ÿå¿«é€Ÿæ‰¾åˆ°å¯¹çš„çµæ„Ÿã€‚OpenClaw å¸®æˆ‘åšåˆ°äº†è¿™ä¸€ç‚¹ã€‚

---

*æœ¬æ–‡é¦–å‘äºè…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒºï¼Œæ ‡ç­¾ï¼šç©è½¬OpenClawäº‘ç«¯åˆ›æ„å®è·µ*

**ä½œè€…ç®€ä»‹**ï¼šæŠ€æœ¯åšä¸»ï¼Œä¸“æ³¨äº‘åŸç”Ÿå’Œ AI åº”ç”¨å¼€å‘ï¼Œæ­£åœ¨ç”¨ AI é‡å¡‘å·¥ä½œæµã€‚
